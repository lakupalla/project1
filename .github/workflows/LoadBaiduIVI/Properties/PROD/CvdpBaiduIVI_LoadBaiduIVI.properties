###########################################################################
# Project Configuration
###########################################################################
project=BaiduIVI
fileName=BaiduIVI
workflow=LoadBaiduIVI

##########
# Tables -- Note: table names must be in lowercase (hdfs folder)
##########
table_master=nscvp73_baidu_ivi_pii_hte
table_public_dup_key=nscvd73_baidu_ivi_dup_hte
table_stage=nscvs73_baidu_ivi_st_hte
table_stage_non_dup=nscvz73_baidu_ivi_nondup_st_hte
table_stage_temp_dup_key=nscve73_baidu_ivi_temp_dup_st_hte
table_invalid=ncvdch4_cvdp_invalid_data_sec_hte


###########################################################################
# Environment Based Configuration (Dev/QA/Prod)
###########################################################################

environment_hdfs_folder=/project/CVDP/CVDPPRD

#Workflow Step: Authservice_Input_Move,
hdfs_mass_move_class=com.ford.it.cvdp.driver.HdfsMassFileMove

# Path Configuration - NAS
# ------------------------
path_edge_node_root=/e/cvdpprdp

# Path Configuration - HDFS
# -------------------------
path_custom_jar_lib=${environment_hdfs_folder}/Workflow/lib
path_hdfs_workflow_root=${environment_hdfs_folder}/Workflow/${fileName}/Workflows/${workflow}
path_hdfs_common_root=${environment_hdfs_folder}/Workflow/Common/Workflows/Common
path_hdfs_sharelib_hive=/user/oozie/share/lib/hive2/
path_hdfs_sharelib_hbase=/user/oozie/share/lib/hbase/

path_hdfs_secure=${environment_hdfs_folder}/Warehouse/Secure/${project}
path_hdfs_public=${environment_hdfs_folder}/Warehouse/public/${project}
path_hdfs_staging=${environment_hdfs_folder}/Warehouse/Staging/${project}
path_hdfs_raw=${path_hdfs_staging}/Raw
path_hdfs_input=${path_hdfs_staging}/Input
path_hdfs_inprocess=${path_hdfs_staging}/Inprocess
path_hdfs_transformed=${path_hdfs_staging}/Output
path_hdfs_transfored_bad=${path_hdfs_transformed}/BadRecords
path_hdfs_transformed_good=${path_hdfs_transformed}/GoodRecords
path_hdfs_success=${environment_hdfs_folder}/Archive/${project}/Completed
path_hdfs_failure=${environment_hdfs_folder}/Archive/${project}/Failure
path_hdfs_st_table=${path_hdfs_staging}/${table_stage}
path_hdfs_nondup_st_table=${path_hdfs_staging}/${table_stage_non_dup}
path_hdfs_temp_dup_st_table=${path_hdfs_staging}/${table_stage_temp_dup_key}

#----------------Bad records----------------
path_hdfs_invalid=${environment_hdfs_folder}/Warehouse/Secure/Invalid_data/ncvdch4_cvdp_invalid_data_sec_hte/cvdch4_file_type_c=${fileName}


# Metrics table path
# -------------------
#path_hdfs_metrics=${environment_hdfs_folder}/Warehouse/Public/METRICS
path_hdfs_metrics=${environment_hdfs_folder}/Warehouse/Public/METRICS/ncvda02_workflow_metrics_adm_hte/cvda02_file_typ_c=${fileName}
metrics_driver_class=com.ford.it.cvdp.driver.MetricsDriver
metrics_calculator_class=com.ford.it.cvdp.process.metrics.JsonMetricsCalculator

###########################################################################
#Hadoop Configuration
###########################################################################

# Cluster Configuration
# ---------------------

name_node=hdfs://cnp2cluster:8020
job_tracker=hpccnp2i4.hpccn.ford.com:8050
log_viewer1=https://hpccnp2e.hpccn.ford.com:8000/oozie/list_oozie_workflow
log_viewer2=http://hpccnp2i2.hpccn.ford.com:11000/oozie/v1/job
log_viewer3=http://hpccnp2i2.hpccn.ford.com:11000/oozie?job=

# Kerberos Configuration
# ----------------------

kerberos_user_name=${user.name}
kerberos_principal=${user.name}@HPCCN.FORD.COM
kerberos_keytab_filename=${user.name}.keytab
kerberos_keytab_file=${environment_hdfs_folder}/Workflow/KEYS/${kerberos_keytab_filename}

###########################################################################
#Descriptionforthisparameter{workflow_execution_type}
###########################################################################
# This parameter value should be 'I'. I represents incremental load
# Incremental load always fetch yesterday date data from the cloud
workflow_execution_type=I

# Hive Configuration
# ------------------

hive_database_name=cvdp
hive_beeline_server=jdbc:hive2://hpccnp2-zk-1.hpccn.ford.com:2181,hpccnp2e-zk-2.hpccn.ford.com:2181,hpccnp2x-zk-3.hpccn.ford.com:2181/;serviceDiscoveryMode=zooKeeper;zooKeeperNamespace=hiveserver2-apps
hive_kerberos_principal=hive/_HOST@HPCCN.FORD.COM

# Hive Tez Memory Configuration
# -----------------------------

hive_tez_vectorization_enabled=false
hive_tez_java_opts=-Xmx24576m
hive_tez_container_size=32768

###########################################################################
# Workflow  Configuration
###########################################################################

# Oozie Configuration
# -------------------

oozie_queue_name=cvdp
oozie.coord.application.path=${name_node}${path_hdfs_workflow_root}
oozie.libpath=${path_hdfs_workflow_root},${path_custom_jar_lib}/lib,${path_custom_jar_lib}/CvdpCommon.jar,${path_custom_jar_lib}/CvdpBaiduIVI.jar,${path_hdfs_sharelib_hive}
oozie.use.system.libpath=true
oozie.launcher.mapreduce.task.classpath.user.precedence=true;
oozie.launcher.mapreduce.user.classpath.first=true;
oozie.launcher.mapreduce.job.user.classpath.first=true;
workflow_path=${path_hdfs_workflow_root}/workflow.xml

# Metrics collection step Configuration
# -------------------
oozie_url=http://hpccnp2i2.hpccn.ford.com:11000/oozie

# Workflow Schedule Configuration
# -------------------------------

frequency_interval=1440
start_date_time_in_utc=2019-05-28T00:00Z
end_date_time_in_utc=2028-12-31T11:20Z

# Workflow Email Configuration
# ----------------------------

email_recipient=CVDPIT@ford.com
email_subject=CVDP PROD: Workflow BaiduIVI_LoadBaiduIVI_WF
